{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "# from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-12):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    mseloss = K.sum(K.square(y_true_f-y_pred_f))\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = K.mean( (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) )\n",
    "    return 0.5*(1-dice)+1.5*K.mean(mseloss)\n",
    "\n",
    "\n",
    "\n",
    "def plot_sample(X, preds,output_dir, ix=None ,im_width=128):\n",
    "    lung_area = 0\n",
    "    ild_area = 0\n",
    "    \n",
    "    for i in range(im_width):\n",
    "        for j in range(im_width):\n",
    "            if X[ix][i][j] > 0.03:\n",
    "                lung_area+=1\n",
    "    \n",
    "    \n",
    "    output = preds[ix].squeeze()\n",
    "    new = []\n",
    "    for i in range(im_width):\n",
    "        new.append([])    \n",
    "        for j in range(im_width):\n",
    "            new[i].append(output[i][j])\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "    I = np.dstack([X[ix, ..., 0], X[ix, ..., 0], X[ix, ..., 0]])\n",
    "    for i in range(im_width):\n",
    "        for j in range(im_width):\n",
    "            new[i][j] = sigmoid(new[i][j])\n",
    "            if new[i][j] > 0.57:\n",
    "                new[i][j] = 255\n",
    "                I[i, j, :] = [1, 0, 0]\n",
    "                ild_area+=1\n",
    "            else:\n",
    "                new[i][j] = 0\n",
    "                \n",
    "    ax.set_title('overlap')    \n",
    "    ax.imshow(X[ix, ..., 0],cmap='gray')\n",
    "    ax.imshow(I,alpha=0.5)\n",
    "\n",
    "    fig.savefig(output_dir+str(ix)+'.png')\n",
    "    rv = ild_area/lung_area\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_ild(file_list,path_data,output_dir):\n",
    "    #scale data's height and width\n",
    "    im_width = 128\n",
    "    im_height = 128\n",
    "    index = 0\n",
    "    rf_list = []\n",
    "    rv_list = []\n",
    "    \n",
    "    #preprocess the data\n",
    "    x_new = np.zeros(( len(file_list), im_height, im_width, 1), dtype=np.float32)\n",
    "    for fname in file_list:\n",
    "        img = load_img(path_data + fname, grayscale=True)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
    "        # Save images\n",
    "        x_new[index, ..., 0] = x_img.squeeze() / 255\n",
    "        index += 1\n",
    "    #declare the model\n",
    "    input_img = Input((im_height, im_width, 1), name='img')\n",
    "    model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "    model.compile(optimizer=Adam(), loss=dice_loss, metrics=[\"accuracy\"])\n",
    "    #load weight \n",
    "    model.load_weights('model-tgs-salt.h5')\n",
    "    #predict the data\n",
    "    preds_val = model.predict(x_new,batch_size=1, verbose=1)\n",
    "    #plot the data\n",
    "    for i in range(len(file_list)):\n",
    "        t = plot_sample(x_new, preds_val,output_dir=output_dir,ix=i)\n",
    "        rf_list.append(output_dir+str(i)+'.png')\n",
    "        rv_list.append(t)\n",
    "    return rf_list,rv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_list = ['ILD05_18.jpg','ILD05_39.jpg','ILD05_80.jpg']\n",
    "    path_data='../../../Desktop/new5/img/'\n",
    "    output_dir='../../output_pic_unet2/'\n",
    "    \n",
    "    return_file_list , return_value_list = pred_ild(file_list,path_data,output_dir)\n",
    "    print(return_file_list)\n",
    "    print(return_value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
