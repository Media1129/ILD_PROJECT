{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "# plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "# from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "border = 5\n",
    "path_data = '../../../Desktop/training/img/'\n",
    "path_label = '../../../Desktop/training/label/'\n",
    "train_num = 2266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "\n",
    "x = np.zeros((train_num, im_height, im_width, 1), dtype=np.float32)\n",
    "y = np.zeros((train_num, im_height, im_width, 1), dtype=np.float32)\n",
    "\n",
    "index = 0\n",
    "for fname in os.listdir(path_data):\n",
    "    img = load_img(path_data + fname, grayscale=True)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "    img = load_img(path_label + fname, grayscale=True)\n",
    "    y_img = img_to_array(img)\n",
    "    y_img = resize(y_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    \n",
    "    \n",
    "    # Save images\n",
    "    x[index, ..., 0] = x_img.squeeze() / 255\n",
    "    y[index] = y_img / 255\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "border = 5\n",
    "path_data = '../../../Desktop/new/img/'\n",
    "path_label = '../../../Desktop/new/label/'\n",
    "predict_len = 172\n",
    "\n",
    "x_new = np.zeros((predict_len, im_height, im_width, 1), dtype=np.float32)\n",
    "y_new = np.zeros((predict_len, im_height, im_width, 1), dtype=np.float32)\n",
    "\n",
    "index = 0\n",
    "for fname in os.listdir(path_data):\n",
    "    img = load_img(path_data + fname, grayscale=True)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "    img = load_img(path_label + fname, grayscale=True)\n",
    "    y_img = img_to_array(img)\n",
    "    y_img = resize(y_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    \n",
    "    \n",
    "    # Save images\n",
    "    x_new[index, ..., 0] = x_img.squeeze() / 255\n",
    "    y_new[index] = y_img / 255\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and valid\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.15, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=callbacks, validation_split=0.3)\n",
    "\n",
    "results = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=callbacks, \n",
    "                    validation_data=(x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-tgs-salt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set (this must be equals to the best log_loss)\n",
    "# model.evaluate(X_valid, y_valid, verbose=1)\n",
    "model.evaluate(x_new, y_new, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "# preds_train = model.predict(x_vali, verbose=1)\n",
    "preds_val   = model.predict(x_new, verbose=1)\n",
    "# preds_val   = model.predict(X_train[1726:1925], verbose=1)\n",
    "\n",
    "\n",
    "# Threshold predictions\n",
    "# preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "# preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, ix=None):\n",
    "    #squeeze() loss one dimension (128,128,1) (128,128)      #softmax use exp() to become[0,1]\n",
    "    output = preds[ix].squeeze()  #     output = softmax(preds[ix].squeeze())*255\n",
    "    new = []\n",
    "    for i in range(128):\n",
    "        new.append([])    \n",
    "        for j in range(128):\n",
    "            new[i].append(output[i][j])\n",
    "            \n",
    "            \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0],cmap='gray')\n",
    "    ax[0].set_title('ILD')\n",
    "    \n",
    "    out_y = y[ix].squeeze()\n",
    "    h = np.dstack([X[ix, ..., 0], X[ix, ..., 0], X[ix, ..., 0]])\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            if out_y[i][j] != 0:\n",
    "                h[i, j, :] = [1, 0, 0]\n",
    "    \n",
    "\n",
    "    ax[1].set_title('LABEL')\n",
    "    ax[1].imshow(X[ix, ..., 0],cmap='gray')\n",
    "    ax[1].imshow(h,alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "    ax[2].imshow(new)\n",
    "    ax[2].set_title(\"direct predict\")\n",
    "    \n",
    "    I = np.dstack([X[ix, ..., 0], X[ix, ..., 0], X[ix, ..., 0]])\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            new[i][j] = sigmoid(new[i][j])*255\n",
    "            if new[i][j] < 125 or new[i][j] > 129:\n",
    "                new[i][j] = 255\n",
    "                I[i, j, :] = [1, 0, 0]\n",
    "            else:\n",
    "                new[i][j] = 0\n",
    "                \n",
    "    ax[3].set_title('overlap')    \n",
    "    ax[3].imshow(X[ix, ..., 0],cmap='gray')\n",
    "    ax[3].imshow(I,alpha=0.5)\n",
    "    \n",
    "\n",
    "    fig.savefig('../../output_pic_unet2/'+str(ix)+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return scipy.special.softmax(x)\n",
    "import math\n",
    "def sigmoid(x):\n",
    "#     print(x.shape)\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(172):\n",
    "    plot_sample(x_new, y_new, preds_val,ix=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "count = 0\n",
    "for i in range(172):\n",
    "    white_sum = 0\n",
    "    white_overlap = 0\n",
    "    Dice = 0\n",
    "     \n",
    "\n",
    "    for j in range(128):\n",
    "        for k in range(128):\n",
    "            if y_new[i, j, k, 0]*255 >= 10:\n",
    "                white_sum += 1\n",
    "            if preds_val[i, j, k, 0]*255 > 10:\n",
    "                white_sum += 1\n",
    "            if y_new[i, j, k, 0]*255 >= 10 and preds_val[i, j, k, 0]*255 > 10:\n",
    "                white_overlap += 1\n",
    "    if white_sum != 0:\n",
    "        Dice = (2*white_overlap) / white_sum\n",
    "    else:\n",
    "        Dice=0\n",
    "    \n",
    "    if(Dice!=0):\n",
    "        total+=Dice\n",
    "        count+=1\n",
    "        print(Dice)\n",
    "print()\n",
    "print(\"average Dice:\")\n",
    "print(total/count)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
