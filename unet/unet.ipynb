{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "# plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "# from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "border = 5\n",
    "path_data = '../../../Desktop/training9/img/'\n",
    "path_label = '../../../Desktop/training9/label/'\n",
    "train_num = 590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "\n",
    "x = np.zeros((train_num, im_height, im_width, 1), dtype=np.float32)\n",
    "y = np.zeros((train_num, im_height, im_width, 1), dtype=np.float32)\n",
    "\n",
    "index = 0\n",
    "for fname in os.listdir(path_data):\n",
    "    img = load_img(path_data + fname, grayscale=True)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "    img = load_img(path_label + fname, grayscale=True)\n",
    "    y_img = img_to_array(img)\n",
    "    y_img = resize(y_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    \n",
    "    \n",
    "    # Save images\n",
    "    x[index, ..., 0] = x_img.squeeze() / 255\n",
    "    y[index] = y_img / 255\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "border = 5\n",
    "path_data = '../../../Desktop/new5/img/'\n",
    "path_label = '../../../Desktop/new5/label/'\n",
    "predict_len = 131\n",
    "\n",
    "x_new = np.zeros((predict_len, im_height, im_width, 1), dtype=np.float32)\n",
    "y_new = np.zeros((predict_len, im_height, im_width, 1), dtype=np.float32)\n",
    "\n",
    "index = 0\n",
    "for fname in os.listdir(path_data):\n",
    "    img = load_img(path_data + fname, grayscale=True)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "    img = load_img(path_label + fname, grayscale=True)\n",
    "    y_img = img_to_array(img)\n",
    "    y_img = resize(y_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    \n",
    "    \n",
    "    # Save images\n",
    "    x_new[index, ..., 0] = x_img.squeeze() / 255\n",
    "    y_new[index] = y_img / 255\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and valid\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.15, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, smooth=1e-12):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "\n",
    "    return 1-K.mean( (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) )\n",
    "# def dice_loss(y_true,y_pred):\n",
    "#     numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "#     denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "\n",
    "#     return 1 - (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=dice_loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=callbacks, validation_split=0.3)\n",
    "\n",
    "results = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks=callbacks, \n",
    "                    validation_data=(x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-tgs-salt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set (this must be equals to the best log_loss)\n",
    "# model.evaluate(X_valid, y_valid, verbose=1)\n",
    "model.evaluate(x_new, y_new, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val   = model.predict(x_new, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, ix=None):\n",
    "    #squeeze() loss one dimension (128,128,1) (128,128)      #softmax use exp() to become[0,1]\n",
    "    output = preds[ix].squeeze()  #     output = softmax(preds[ix].squeeze())*255\n",
    "    new = []\n",
    "    for i in range(128):\n",
    "        new.append([])    \n",
    "        for j in range(128):\n",
    "            new[i].append(output[i][j])\n",
    "            \n",
    "            \n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0],cmap='gray')\n",
    "    ax[0].set_title('ILD')\n",
    "    \n",
    "    out_y = y[ix].squeeze()\n",
    "    h = np.dstack([X[ix, ..., 0], X[ix, ..., 0], X[ix, ..., 0]])\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            if out_y[i][j] != 0:\n",
    "                h[i, j, :] = [1, 0, 0]\n",
    "    \n",
    "\n",
    "    ax[1].set_title('LABEL')\n",
    "    ax[1].imshow(X[ix, ..., 0],cmap='gray')\n",
    "    ax[1].imshow(h,alpha=0.5)\n",
    "\n",
    "    \n",
    "\n",
    "    ax[2].imshow(new)\n",
    "    ax[2].set_title(\"direct predict\")\n",
    "    \n",
    "    I = np.dstack([X[ix, ..., 0], X[ix, ..., 0], X[ix, ..., 0]])\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            new[i][j] = sigmoid(new[i][j])\n",
    "            if new[i][j] > 0.53:\n",
    "                new[i][j] = 255\n",
    "                I[i, j, :] = [1, 0, 0]\n",
    "            else:\n",
    "                new[i][j] = 0\n",
    "                \n",
    "    ax[3].set_title('overlap')    \n",
    "    ax[3].imshow(X[ix, ..., 0],cmap='gray')\n",
    "    ax[3].imshow(I,alpha=0.5)\n",
    "    \n",
    "\n",
    "#     fig.savefig('../../output_pic_unet2/'+str(ix)+'.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "for i in range(predict_len):\n",
    "    plot_sample(x_new, y_new, preds_val,ix=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate the dice \n",
    "for k in range(500,640,10):\n",
    "    dice_thre = k/1000\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for i in range(predict_len):\n",
    "        white_sum = 0\n",
    "        white_overlap = 0\n",
    "        Dice = 0\n",
    "\n",
    "        oriy  = y_new[i].squeeze()\n",
    "        predy = preds_val[i].squeeze()\n",
    "\n",
    "        new_oriy = []\n",
    "        for a in range(128):\n",
    "            new_oriy.append([])    \n",
    "            for b in range(128):\n",
    "                if(  oriy[a][b]  > 0.03 ):\n",
    "                    new_oriy[a].append(1)\n",
    "                else:\n",
    "                    new_oriy[a].append(0)\n",
    "\n",
    "        new_predy = []\n",
    "        for a in range(128):\n",
    "            new_predy.append([])\n",
    "            for b in range(128):\n",
    "                if(sigmoid(predy[a][b])>dice_thre):\n",
    "                    new_predy[a].append(1)\n",
    "                else:\n",
    "                    new_predy[a].append(0)\n",
    "        \n",
    "\n",
    "        for j in range(128):\n",
    "            for k in range(128):\n",
    "                if new_oriy[j][k]:\n",
    "                    white_sum+=1\n",
    "                if new_predy[j][k]:\n",
    "                    white_sum+=1\n",
    "                if new_oriy[j][k] and new_predy[j][k]:\n",
    "                    white_overlap+=1\n",
    "\n",
    "        if white_sum != 0:\n",
    "            Dice = (2*white_overlap) / white_sum\n",
    "        else:\n",
    "            Dice=0\n",
    "\n",
    "        if(Dice!=0):\n",
    "            total+=Dice\n",
    "            count+=1\n",
    "\n",
    "    print(\"dice_threshold: \",end=\"\")\n",
    "    print(dice_thre,end=\"  \")\n",
    "    print(\"average Dice: \",end=\" \")\n",
    "    if count == 0:\n",
    "        print(\"{:.2f}\".format(0))\n",
    "    else:\n",
    "        print(\"{:.2f}\".format(total/count))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate the dice \n",
    "# for k in range(530,570,1):\n",
    "#     dice_thre = k/1000\n",
    "#     total = 0\n",
    "#     count = 0\n",
    "#     for i in range(predict_len):\n",
    "#         white_sum = 0\n",
    "#         white_overlap = 0\n",
    "#         Dice = 0\n",
    "\n",
    "#         oriy  = y_new[i].squeeze()\n",
    "#         predy = preds_val[i].squeeze()\n",
    "\n",
    "#         new_oriy = []\n",
    "#         for a in range(128):\n",
    "#             new_oriy.append([])    \n",
    "#             for b in range(128):\n",
    "#                 if(  oriy[a][b]  > 0.03 ):\n",
    "#                     new_oriy[a].append(1)\n",
    "#                 else:\n",
    "#                     new_oriy[a].append(0)\n",
    "\n",
    "#         new_predy = []\n",
    "#         for a in range(128):\n",
    "#             new_predy.append([])\n",
    "#             for b in range(128):\n",
    "#                 if(sigmoid(predy[a][b])>dice_thre):\n",
    "#                     new_predy[a].append(1)\n",
    "#                 else:\n",
    "#                     new_predy[a].append(0)\n",
    "\n",
    "\n",
    "#         for j in range(128):\n",
    "#             for k in range(128):\n",
    "#                 if new_oriy[j][k]:\n",
    "#                     white_sum+=1\n",
    "#                 if new_predy[j][k]:\n",
    "#                     white_sum+=1\n",
    "#                 if new_oriy[j][k] and new_predy[j][k]:\n",
    "#                     white_overlap+=1\n",
    "\n",
    "#         if white_sum != 0:\n",
    "#             Dice = (2*white_overlap) / white_sum\n",
    "#         else:\n",
    "#             Dice=0\n",
    "\n",
    "#         if(Dice!=0):\n",
    "#             total+=Dice\n",
    "#             count+=1\n",
    "\n",
    "#     print(\"dice_threshold: \",end=\"\")\n",
    "#     print(dice_thre,end=\"  \")\n",
    "#     print(\"average Dice: \",end=\" \")\n",
    "#     if count == 0:\n",
    "#         print(\"{:.2f}\".format(0))\n",
    "#     else:\n",
    "#         print(\"{:.2f}\".format(total/count))\n",
    "#     print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
